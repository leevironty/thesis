# PESP original introduction
@article{pesp-original-1989,
  title={A mathematical model for periodic scheduling problems},
  author={Serafini, Paolo and Ukovich, Walter},
  journal={SIAM Journal on Discrete Mathematics},
  volume={2},
  number={4},
  pages={550--581},
  year={1989},
  publisher={SIAM}
}

# TimPass original formulation
@book{timpass-original-2014,
  title={Integrating routing decisions in public transportation problems},
  author={Schmidt, Marie E and others},
  year={2014},
  publisher={Springer}
}

# Philinen TimPass formulaatio, lisäksi SAT-näkökulma, kun tää kuitenkin on PESP ekstensio
# Tässä kans node-arc incidence matrix kuvaus
@inproceedings{sat-philine-gattermann2016integrating,
  title={Integrating passengers' routes in periodic timetabling: a SAT approach},
  author={Gattermann, Philine and Gro{\ss}mann, Peter and Nachtigall, Karl and Sch{\"o}bel, Anita},
  booktitle={16th Workshop on Algorithmic Approaches for Transportation Modelling, Optimization, and Systems (ATMOS 2016)},
  year={2016},
  organization={Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik}
}


# TimPass preprocessing, heuristic with only partial rerouting of passengers
@article{schiewe2020periodic,
  title={Periodic timetabling with integrated routing: Toward applicable approaches},
  author={Schiewe, Philine and Sch{\"o}bel, Anita},
  journal={Transportation Science},
  volume={54},
  number={6},
  pages={1714--1731},
  year={2020},
  publisher={INFORMS}
}

# sequential optimization formalisation, "price of sequentiality" introduction
# tästä voi salee ottaa jotain demoja, joilla voi osoittaa TimPass -ongelman olevan tärkeä
@article{schiewe2022integrated,
  title={Integrated optimization of sequential processes: General analysis and application to public transport},
  author={Schiewe, Philine and Sch{\"o}bel, Anita},
  journal={EURO Journal on Transportation and Logistics},
  volume={11},
  pages={100073},
  year={2022},
  publisher={Elsevier}
}



# PESP Berlin metro case study, np-hardness
@inproceedings{liebchen2007periodic,
  title={Periodic timetable optimization in public transport},
  author={Liebchen, Christian},
  booktitle={Operations Research Proceedings 2006: Selected Papers of the Annual International Conference of the German Operations Research Society (GOR), Jointly Organized with the Austrian Society of Operations Research ({\"O}GOR) and the Swiss Society of Operations Research (SVOR) Karlsruhe, September 6--8, 2006},
  pages={29--36},
  year={2007},
  organization={Springer}
}


# Modulo network simplex heuristic from PESP to TimPass 
@inproceedings{lobel2020restricted,
  title={The restricted modulo network simplex method for integrated periodic timetabling and passenger routing},
  author={L{\"o}bel, Fabian and Lindner, Niels and Bornd{\"o}rfer, Ralf},
  booktitle={Operations Research Proceedings 2019: Selected Papers of the Annual International Conference of the German Operations Research Society (GOR), Dresden, Germany, September 4-6, 2019},
  pages={757--763},
  year={2020},
  organization={Springer}
}


# SAT-hypen alku, SAT for PESP
@inproceedings{grossmann2012solving,
  title={Solving periodic event scheduling problems with SAT},
  author={Gro{\ss}mann, Peter and H{\"o}lldobler, Steffen and Manthey, Norbert and Nachtigall, Karl and Opitz, Jens and Steinke, Peter},
  booktitle={Advanced Research in Applied Artificial Intelligence: 25th International Conference on Industrial Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2012, Dalian, China, June 9-12, 2012. Proceedings 25},
  pages={166--175},
  year={2012},
  organization={Springer}
}


# Integrated optimization importance, chicken & egg view, passenger point of view
@article{schmidt2015complexity,
  title={The complexity of integrating passenger routing decisions in public transportation models},
  author={Schmidt, Marie and Sch{\"o}bel, Anita},
  journal={Networks},
  volume={65},
  number={3},
  pages={228--243},
  year={2015},
  publisher={Wiley Online Library}
}


# TimPassLib
@article{schiewe2023introducing,
  title={Introducing TimPassLib--A library for integrated periodic timetabling and passenger routing},
  author={Schiewe, Philine and Goerigk, Marc and Lindner, Niels},
  year={2023}
}



# --------------------------- ML in public transport ---------------------------

# inproceedings
@comment{darwish2020optimising,
  title={Optimising public bus transit networks using deep reinforcement learning},
  author={Darwish, Ahmed and Khalil, Momen and Badawi, Karim},
  booktitle={2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)},
  pages={1--7},
  year={2020},
  organization={IEEE}
}

# article
@comment{yan2022distributed,
  title={Distributed Multiagent Deep Reinforcement Learning for Multiline Dynamic Bus timetable optimization},
  author={Yan, Haoyang and Cui, Zhiyong and Chen, Xinqiang and Ma, Xiaolei},
  journal={IEEE Transactions on Industrial Informatics},
  volume={19},
  number={1},
  pages={469--479},
  year={2022},
  publisher={IEEE}
}




# -------------------------- ML in combinatorial opt ---------------------------


@article{zhang2023survey,
  title={A survey for solving mixed integer programming via machine learning},
  author={Zhang, Jiayi and Liu, Chang and Li, Xijun and Zhen, Hui-Ling and Yuan, Mingxuan and Li, Yawen and Yan, Junchi},
  journal={Neurocomputing},
  volume={519},
  pages={205--217},
  year={2023},
  publisher={Elsevier}
}




# GNN introduction


@ARTICLE{gnn-intro-2009,
  author={Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele},
  journal={IEEE Transactions on Neural Networks}, 
  title={The Graph Neural Network Model}, 
  year={2009},
  volume={20},
  number={1},
  pages={61-80},
  doi={10.1109/TNN.2008.2005605}
}


@article{gnn-review-2020,
    title = {Graph neural networks: A review of methods and applications},
    journal = {AI Open},
    volume = {1},
    pages = {57-81},
    year = {2020},
    issn = {2666-6510},
    doi = {https://doi.org/10.1016/j.aiopen.2021.01.001},
    url = {https://www.sciencedirect.com/science/article/pii/S2666651021000012},
    author = {Jie Zhou and Ganqu Cui and Shengding Hu and Zhengyan Zhang and Cheng Yang and Zhiyuan Liu and Lifeng Wang and Changcheng Li and Maosong Sun},
    keywords = {Deep learning, Graph neural network},
    abstract = {Lots of learning tasks require dealing with graph data which contains rich relation information among elements. Modeling physics systems, learning molecular fingerprints, predicting protein interface, and classifying diseases demand a model to learn from graph inputs. In other domains such as learning from non-structural data like texts and images, reasoning on extracted structures (like the dependency trees of sentences and the scene graphs of images) is an important research topic which also needs graph reasoning models. Graph neural networks (GNNs) are neural models that capture the dependence of graphs via message passing between the nodes of graphs. In recent years, variants of GNNs such as graph convolutional network (GCN), graph attention network (GAT), graph recurrent network (GRN) have demonstrated ground-breaking performances on many deep learning tasks. In this survey, we propose a general design pipeline for GNN models and discuss the variants of each component, systematically categorize the applications, and propose four open problems for future research.}
}


@InProceedings{mpgnn-into-2017,
  title = 	 {Neural Message Passing for Quantum Chemistry},
  author =       {Justin Gilmer and Samuel S. Schoenholz and Patrick F. Riley and Oriol Vinyals and George E. Dahl},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {1263--1272},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/gilmer17a/gilmer17a.pdf},
  url = 	 {https://proceedings.mlr.press/v70/gilmer17a.html},
  abstract = 	 {Supervised learning on molecules has incredible potential to be useful in chemistry, drug discovery, and materials science. Luckily, several promising and closely related neural network models invariant to molecular symmetries have already been described in the literature. These models learn a message passing algorithm and aggregation procedure to compute a function of their entire input graph. At this point, the next step is to find a particularly effective variant of this general approach and apply it to chemical prediction benchmarks until we either solve them or reach the limits of the approach. In this paper, we reformulate existing models into a single common framework we call Message Passing Neural Networks (MPNNs) and explore additional novel variations within this framework. Using MPNNs we demonstrate state of the art results on an important molecular property prediction benchmark; these results are strong enough that we believe future work should focus on datasets with larger molecules or more accurate ground truth labels.}
}


@article{adam-2014,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}


@inproceedings{repr-limit-2020,
  title={Generalization and representational limits of graph neural networks},
  author={Garg, Vikas and Jegelka, Stefanie and Jaakkola, Tommi},
  booktitle={International Conference on Machine Learning},
  pages={3419--3430},
  year={2020},
  organization={PMLR}
}


@article{LaPE-implementation-2020,
  author       = {Vijay Prakash Dwivedi and
                  Chaitanya K. Joshi and
                  Thomas Laurent and
                  Yoshua Bengio and
                  Xavier Bresson},
  title        = {Benchmarking Graph Neural Networks},
  journal      = {CoRR},
  volume       = {abs/2003.00982},
  year         = {2020},
  url          = {https://arxiv.org/abs/2003.00982},
  eprinttype    = {arXiv},
  eprint       = {2003.00982},
  timestamp    = {Sat, 23 Jan 2021 01:14:30 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2003-00982.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@ARTICLE{LaPE-first-introduction-2003,
  author={Belkin, Mikhail and Niyogi, Partha},
  journal={Neural Computation}, 
  title={Laplacian Eigenmaps for Dimensionality Reduction and Data Representation}, 
  year={2003},
  volume={15},
  number={6},
  pages={1373-1396},
  doi={10.1162/089976603321780317}
}


@inproceedings{hgt-2020,
  title={Heterogeneous graph transformer},
  author={Hu, Ziniu and Dong, Yuxiao and Wang, Kuansan and Sun, Yizhou},
  booktitle={Proceedings of the web conference 2020},
  pages={2704--2710},
  year={2020}
}


@inproceedings{line-graph-trick,
  title={Relation structure-aware heterogeneous graph neural network},
  author={Zhu, Shichao and Zhou, Chuan and Pan, Shirui and Zhu, Xingquan and Wang, Bin},
  booktitle={2019 IEEE international conference on data mining (ICDM)},
  pages={1534--1539},
  year={2019},
  organization={IEEE}
}

@article{gelus,
  title={Gaussian error linear units (gelus)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}


@article{cycle-basis-applications-2009,
  title={Cycle bases in graphs characterization, algorithms, complexity, and applications},
  author={Kavitha, Telikepalli and Liebchen, Christian and Mehlhorn, Kurt and Michail, Dimitrios and Rizzi, Romeo and Ueckerdt, Torsten and Zweig, Katharina A},
  journal={Computer Science Review},
  volume={3},
  number={4},
  pages={199--243},
  year={2009},
  publisher={Elsevier}
}

@incollection{cycle-basis-original-2001,
  title={A cycle based optimization model for the cyclic railway timetabling problem},
  author={Peeters, Leon and Kroon, Leo},
  booktitle={Computer-aided scheduling of public transport},
  pages={275--296},
  year={2001},
  publisher={Springer}
}


@unpublished{helmi,
  author = {Hankimaa, Helmi},
  note   = {Unpublished MSc thesis},
  title  = {Optimising energy and reserve offers in the Nordic markets under uncertainty},
  year   = {2023},
  url = {https://urn.fi/URN:NBN:fi:aalto-202308275171}
}
# CITED


### Deep L & public transport

@article{DRL-timetabling-yan2022distributed,
  title={Distributed Multiagent Deep Reinforcement Learning for Multiline Dynamic Bus timetable optimization},
  author={Yan, Haoyang and Cui, Zhiyong and Chen, Xinqiang and Ma, Xiaolei},
  journal={IEEE Transactions on Industrial Informatics},
  volume={19},
  number={1},
  pages={469--479},
  year={2022},
  publisher={IEEE}
}
# file:///Users/leevi/Downloads/Distributed_Multiagent_Deep_Reinforcement_Learning_for_Multiline_Dynamic_Bus_Timetable_Optimization.pdf
# Multi-agent bus timetable optimization, aperiodic setting, Beijin case study
# Action space: drive / don't drive
# RL method: Ape-X Deep Q network (eli replay ish)
# CITED

@inproceedings{darwish2020optimising,
  title={Optimising public bus transit networks using deep reinforcement learning},
  author={Darwish, Ahmed and Khalil, Momen and Badawi, Karim},
  booktitle={2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)},
  pages={1--7},
  year={2020},
  organization={IEEE}
}
# file:///Users/leevi/Downloads/optimising_Public_Bus_Transit_Networks_Using_Deep_Reinforcement_Learning.pdf
# TNDFPS, eli käytännössä lince concept-suunnittelu
# Deep RL, ilmeisesti policy gradient?
# käytännössä enc-dec transformeri
# CITED

@article{kool2018attention,
  title={Attention, learn to solve routing problems!},
  author={Kool, Wouter and Van Hoof, Herke and Welling, Max},
  journal={arXiv preprint arXiv:1803.08475},
  year={2018}
}
# https://arxiv.org/pdf/1803.08475.pdf
# Routing w/ reinforcement learning & transformers, inspiraatio ylemmälle
# CITED


@article{matos2021solving,
  title={Solving periodic timetabling problems with SAT and machine learning},
  author={Matos, Gon{\c{c}}alo P and Albino, Lu{\'\i}s M and Saldanha, Ricardo L and Morgado, Ernesto M},
  journal={Public Transport},
  volume={13},
  number={3},
  pages={625--648},
  year={2021},
  publisher={Springer}
}
# https://link.springer.com/article/10.1007/s12469-020-00244-y
# SAT approach w/ RL heuristic
# RL guides the SAT solver -> decision problem
# menee vähän vikaan kategoriaan, mut kans tähän, koska PESP
# CITED


@article{MULLERHANNEMANN2022103566,
    title = {Estimating the robustness of public transport schedules using machine learning},
    journal = {Transportation Research Part C: Emerging Technologies},
    volume = {137},
    pages = {103566},
    year = {2022},
    issn = {0968-090X},
    doi = {https://doi.org/10.1016/j.trc.2022.103566},
    url = {https://www.sciencedirect.com/science/article/pii/S0968090X22000146},
    author = {Matthias Müller-Hannemann and Ralf Rückert and Alexander Schiewe and Anita Schöbel},
    keywords = {Public transportation, Scheduling, Timetabling, Machine learning, Robustness, Optimization},
abstract = {The planning of attractive and cost efficient public transport schedules, i.e., timetables and corresponding vehicle schedules is a highly complex optimization process involving many steps. Integrating robustness from a passenger’s point of view makes the task even more challenging. With numerous different definitions of robustness in the literature, a standard way to evaluate the robustness of a public transport system is to simulate its performance under a large number of possible scenarios. Unfortunately, this is computationally very expensive. In this paper, we therefore explore a new way of such a scenario-based robustness approximation by using regression models from machine learning. Training of these models is based on carefully selected key features of public transport systems and passenger demand. The trained model is then able to predict the robustness of untrained instances with high accuracy using only its key features, allowing for a robustness oracle for transport planners that approximates the robustness in constant time. Such an oracle can be used as black box to increase the robustness of public transport schedules. We provide a first proof of concept for the special case of robust timetabling, using a local search framework. In computational experiments with different benchmark instances we demonstrate an excellent quality of our predictions.}
}
# https://www.sciencedirect.com/science/article/pii/S0968090X22000146#fig5
# Timetable robustness estimation w/ trad. ML methods
# monta mallia, ei deep learning tms.
# CITED


### NN in optimization

@article{BENGIO2021405,
    title = {Machine learning for combinatorial optimization: A methodological tour d’horizon},
    journal = {European Journal of Operational Research},
    volume = {290},
    number = {2},
    pages = {405-421},
    year = {2021},
    issn = {0377-2217},
    doi = {https://doi.org/10.1016/j.ejor.2020.07.063},
    url = {https://www.sciencedirect.com/science/article/pii/S0377221720306895},
    author = {Yoshua Bengio and Andrea Lodi and Antoine Prouvost},
    keywords = {Combinatorial optimization, Machine learning, Branch and bound, Mixed-integer programming solvers},
    abstract = {This paper surveys the recent attempts, both from the machine learning and operations research communities, at leveraging machine learning to solve combinatorial optimization problems. Given the hard nature of these problems, state-of-the-art algorithms rely on handcrafted heuristics for making decisions that are otherwise too expensive to compute or mathematically not well defined. Thus, machine learning looks like a natural candidate to make such decisions in a more principled and optimized way. We advocate for pushing further the integration of machine learning and combinatorial optimization and detail a methodology to do so. A main point of the paper is seeing generic optimization problems as data points and inquiring what is the relevant distribution of problems to use for learning on a given task.}
}
# https://www.sciencedirect.com/science/article/pii/S0377221720306895
# CITED

@article{cappart2023combinatorial,
  title={Combinatorial optimization and reasoning with graph neural networks},
  author={Cappart, Quentin and Ch{\'e}telat, Didier and Khalil, Elias B and Lodi, Andrea and Morris, Christopher and Veli{\v{c}}kovi{\'c}, Petar},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={130},
  pages={1--61},
  year={2023}
}
# https://www.jmlr.org/papers/volume24/21-0449/21-0449.pdf



@article{nair2020solving,
  title={Solving mixed integer programs using neural networks},
  author={Nair, Vinod and Bartunov, Sergey and Gimeno, Felix and Von Glehn, Ingrid and Lichocki, Pawel and Lobov, Ivan and O'Donoghue, Brendan and Sonnerat, Nicolas and Tjandraatmadja, Christian and Wang, Pengming and others},
  journal={arXiv preprint arXiv:2012.13349},
  year={2020}
}
# https://arxiv.org/pdf/2012.13349.pdf
# Salee ihan tosi irrelevantti??


@article{ZHANG2023205,
    title = {A survey for solving mixed integer programming via machine learning},
    journal = {Neurocomputing},
    volume = {519},
    pages = {205-217},
    year = {2023},
    issn = {0925-2312},
    doi = {https://doi.org/10.1016/j.neucom.2022.11.024},
    url = {https://www.sciencedirect.com/science/article/pii/S0925231222014035},
    author = {Jiayi Zhang and Chang Liu and Xijun Li and Hui-Ling Zhen and Mingxuan Yuan and Yawen Li and Junchi Yan},
    keywords = {Mixed integer programming, Machine learning, Combinatorial optimization},
    abstract = {Machine learning (ML) has been recently introduced to solving optimization problems, especially for combinatorial optimization (CO) tasks. In this paper, we survey the trend of leveraging ML to solve the mixed-integer programming problem (MIP). Theoretically, MIP is an NP-hard problem, and most CO problems can be formulated as MIP. Like other CO problems, the human-designed heuristic algorithms for MIP rely on good initial solutions and cost a lot of computational resources. Therefore, researchers consider applying machine learning methods to solve MIP since ML-enhanced approaches can provide the solution based on the typical patterns from the training data. Specifically, we first introduce the formulation and preliminaries of MIP and representative traditional solvers. Then, we show the integration of machine learning and MIP with detailed discussions on related learning-based methods, which can be further classified into exact and heuristic algorithms. Finally, we propose the outlook for learning-based MIP solvers, the direction toward more combinatorial optimization problems beyond MIP, and the mutual embrace of traditional solvers and ML components. We maintain a list of papers that utilize machine learning technologies to solve combinatorial optimization problems, which is available at https://github.com/Thinklab-SJTU/awesome-ml4co.}
}
# CITED


### Discussion

@article{alon2020bottleneck,
  title={On the bottleneck of graph neural networks and its practical implications},
  author={Alon, Uri and Yahav, Eran},
  journal={arXiv preprint arXiv:2006.05205},
  year={2020}
}
# Information squashing & implications for long-range interactions (LRI)



@misc{ying2021transformers,
      title={Do Transformers Really Perform Bad for Graph Representation?}, 
      author={Chengxuan Ying and Tianle Cai and Shengjie Luo and Shuxin Zheng and Guolin Ke and Di He and Yanming Shen and Tie-Yan Liu},
      year={2021},
      eprint={2106.05234},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
# Microsoft graphformer

@inproceedings{hussain2022global,
  title={Global self-attention as a replacement for graph convolution},
  author={Hussain, Md Shamim and Zaki, Mohammed J and Subramanian, Dharmashankar},
  booktitle={Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={655--665},
  year={2022}
}
# EGT


@article{hu2021ogblsc,
  title={OGB-LSC: A Large-Scale Challenge for Machine Learning on Graphs},
  author={Hu, Weihua and Fey, Matthias and Ren, Hongyu and Nakata, Maho and Dong, Yuxiao and Leskovec, Jure},
  journal={arXiv preprint arXiv:2103.09430},
  year={2021}
}
# benchmark


@inproceedings{oag-dataset,
    author = {Zhang, Fanjin and Liu, Xiao and Tang, Jie and Dong, Yuxiao and Yao, Peiran and Zhang, Jie and Gu, Xiaotao and Wang, Yan and Shao, Bin and Li, Rui and Wang, Kuansan},
    title = {OAG: Toward Linking Large-scale Heterogeneous Entity Graphs},
    year = {2019},
    isbn = {9781450362016},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi-org.libproxy.aalto.fi/10.1145/3292500.3330785},
    doi = {10.1145/3292500.3330785},
    abstract = {Linking entities from different sources is a fundamental task in building open knowledge graphs. Despite much research conducted in related fields, the challenges of linkinglarge-scale heterogeneous entity graphs are far from resolved. Employing two billion-scale academic entity graphs (Microsoft Academic Graph and AMiner) as sources for our study, we propose a unified framework --- LinKG --- to address the problem of building a large-scale linked entity graph. LinKG is coupled with three linking modules, each of which addresses one category of entities. To link word-sequence-based entities (e.g., venues), we present a long short-term memory network-based method for capturing the dependencies. To link large-scale entities (e.g., papers), we leverage locality-sensitive hashing and convolutional neural networks for scalable and precise linking. To link entities with ambiguity (e.g., authors), we propose heterogeneous graph attention networks to model different types of entities. Our extensive experiments and systematical analysis demonstrate that LinKG can achieve linking accuracy with an F1-score of 0.9510, significantly outperforming the state-of-the-art. LinKG has been deployed to Microsoft Academic Search and AMiner to integrate the two large graphs. We have published the linked results---the Open Academic Graph (OAG)footnoteurlhttps://www.openacademic.ai/oag/ , making it the largest publicly available heterogeneous academic graph to date.},
    booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
    pages = {2585–2595},
    numpages = {11},
    keywords = {entity linking, heterogeneous networks, name ambiguity, oag},
    location = {Anchorage, AK, USA},
    series = {KDD '19}
}